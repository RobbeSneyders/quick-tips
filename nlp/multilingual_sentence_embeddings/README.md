# Multilingual Sentence Embedding techniques

Sentence embedding techniques have come a long way since averaging English Word2Vec vectors.

Transformers have provided us a way to do this in a contextualized manner and on a sentence level, and multilingual advances have opened up these models for non-English business cases.

Check out the notebook how you can leverage multilingual USE and - SentenceBert to encode a piece of non-English text

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/ml6team/quick-tips/blob/nlp/tip_1_multilingual_sentence_embedders/nlp/multilingual_sentence_embeddings/multilingual_sentence_embeddings.ipynb)